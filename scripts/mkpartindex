#!/usr/bin/env python
# SPDX-License-Identifier: BSD-3-Clause
# This script generates the Xylene part index
import json
import logging           as log
from multiprocessing     import  cpu_count
import sys
from io                  import BytesIO
from concurrent.futures  import ThreadPoolExecutor
from datetime            import datetime
from pathlib             import Path

from msgpack             import pack
from zstandard           import ZstdCompressor

from rich.progress       import BarColumn, Progress, SpinnerColumn, TextColumn

from prjxylene.common    import XYLENE_DB_DIR, XYLENE_PI_DIR, main
from prjxylene.templates import render_template
from prjxylene.vivado    import Vivado


RAW_PART_LIST    = (XYLENE_PI_DIR / 'parts_list.json'   )
NORMALIZED_INDEX = (XYLENE_PI_DIR / 'part_index.json'   )
DEDUPED_INDEX    = (XYLENE_PI_DIR / 'unified_index.json')
PART_PROP_DIR    = (XYLENE_PI_DIR / 'properties'        )
SPLIT_DIR        = (XYLENE_PI_DIR / 'family_indices'    )
SERIALIZED_DIR   = (XYLENE_PI_DIR / 'serialized'        )

def _gen_partnumber(part_tuple):
	name        = part_tuple[0]
	package     = part_tuple[1]
	dev_dict    = part_tuple[2]
	part_number = ''

	grade        = dev_dict['speed_variants'][0]['grade']

	# Construct valid part number
	if name[3] == 'u':
		# UltraScale or UltraScale+
		temp_variant = dev_dict['temp_variants'][0]['grade'].lower()
		part_number = f'{name}-{package}{grade}-{temp_variant}'
	elif name[:3] == 'xcu':
		# Alveo devices
		temp_variant = dev_dict['temp_variants'][0]['grade'].lower()
		part_number = f'{name}-{package}{grade}-{temp_variant}'
	elif name == 'xqrvc1902' and package == 'vsra2197':
		# The xqrvc1902-vsra2197 only has -1MM-b-S
		part_number = f'{name}-{package}-1MM-b-S'
	elif name[:3] == 'xqr':
		# TODO: Rad-hard Devices
		temp_variant = dev_dict['temp_variants'][0]['grade'].lower()
		part_number = f'{name}-{package}{grade}-{temp_variant}'
	elif name[:4] in ('xcvm', 'xcvc', 'xcve', 'xcvp', 'xqvc', 'xqvm'):
		# Versal devices
		temp_variant = dev_dict['temp_variants'][0]['grade'].lower()
		part_number = f'{name}-{package}{grade}-{temp_variant}-S'
	elif name == 'xq7z045' and package == 'rfg676':
		# The xq7z045-rfg676 only has the -1QL speed grade
		part_number = f'{name}{package}-1QL'
	elif name[:4] in ('xck26'):
		# Kria-SOMs
		temp_variant = dev_dict['temp_variants'][0]['grade'].lower()
		part_number = f'{name}-{package}{grade}-{temp_variant}'
	else:
		part_number = f'{name}{package}{grade}'

	return part_number

def gen_part_list(args, progress : Progress):
	task = progress.add_task(description = 'Generating Parts list', start = False)
	if not RAW_PART_LIST.exists():
		dump_parts = (XYLENE_PI_DIR / 'dump_parts_list.tcl')
		if not dump_parts.exists():
			with dump_parts.open('w') as tcl_script:
				tcl_script.write(render_template('dump_part_list'))


		if not Vivado.spawn_tcl(
			_log = False, journal = False,
			tcl_file = dump_parts,
			tcl_args = [str(RAW_PART_LIST)]
		):
			if RAW_PART_LIST.exists():
				RAW_PART_LIST.rename(f'{RAW_PART_LIST}.bad')

			return False

	progress.remove_task(task)

	return True

def gen_part_props(args, progress : Progress):
	task = progress.add_task(description = 'Collecting part properties')
	if not PART_PROP_DIR.exists():
		PART_PROP_DIR.mkdir()

	dump_parts_props = (XYLENE_PI_DIR / 'dump_properties.tcl')
	if not dump_parts_props.exists():
		with dump_parts_props.open('w') as tcl_script:
			tcl_script.write(render_template('dump_properties'))

	log.info(f'Loading parts list from {RAW_PART_LIST}')
	with RAW_PART_LIST.open('r') as pl:
		parts_list = json.load(pl)

	part_count = len(parts_list['parts'])

	log.info(f'Loaded {part_count} parts')
	progress.update(task, total = part_count)
	progress.start_task(task)

	def _run_vivado(part):
		out_file = (PART_PROP_DIR / f'{part}.json')

		if out_file.exists():
			return True

		return Vivado.spawn_tcl(
			_log = False, journal = False,
			tcl_file = dump_parts_props,
			tcl_args = [ str(out_file), part ]
		)

	def _update_progress(f):
		if f.result():
			progress.advance(task, 1)

	futures = []
	with ThreadPoolExecutor(args.parallel_jobs) as pool:
		for part in filter(lambda p: p != '', parts_list['parts']):
			f = pool.submit(_run_vivado, part)
			f.add_done_callback(_update_progress)
			futures.append(f)

	success = all(map(lambda f: f.result(), futures))

	progress.remove_task(task)

	return success

def normalize_parts(args, progress : Progress):
	task = progress.add_task(description = 'Normalizing part index')

	log.info(f'Loading parts list from {RAW_PART_LIST}')
	with RAW_PART_LIST.open('r') as pl:
		parts_list = json.load(pl)

	part_count = len(parts_list['parts'])

	log.info(f'Loaded {part_count} parts')
	progress.update(task, total = part_count)

	part_files = map(
		lambda p: (PART_PROP_DIR / f'{p}.json'),
		filter(lambda p: p != '', parts_list['parts'])
	)

	index = {
		'version'  : parts_list['vivado_version'],
		'generated': datetime.now().isoformat(),
		'devices'  : []
	}

	def _get_subclass(family):
		if family[0] == 'q':
			return 'defense-grade'
		elif family[0] == 'a':
			return 'automotive'
		elif family[-1:] == 'l':
			return 'low-voltage'
		else:
			return 'commercial'

	def _get_arch(family, arch_name):
		if family[0] == 'q':
			arch_name = f'Defense-Grade {arch_name}'

		if family[0] == 'a' and family[1] != 'r':
			arch_name = f'Automotive {arch_name}'

		if family[-1:] == 'l':
			arch_name = f'{arch_name} Low Voltage'

		if family[-3:] == 'HBM':
			arch_name = f'{arch_name} HBM'

		if family[-3:] == 'es1':
			arch_name = f'{arch_name} ES1'

		return arch_name

	def _normalize_part(part_file : Path):
		part = None
		with part_file.open('r') as f:
			part = json.load(f)

		part_props = part['properties']

		part_data = {
			'part'    : part['part'],
			'family'  : part_props['FAMILY'],
			'c_family': part_props['C_FAMILY'],
			'package' : part_props['PACKAGE'],
			'device'  : part_props['DEVICE'],
			'speed'   : {
				'subclass': _get_subclass(part_props['FAMILY']),
				'grade'   : part_props['SPEED'],
				'label'   : part_props['SPEED_LABEL'],
				'level'   : {
					'id'  : part_props['SPEED_LEVEL_ID'],
					'date': part_props['SPEED_LEVEL_ID_DATE'],
				},
				'suffix': part_props.get('SPEED_SUFFIX', ''),
			},
			'arch'    : {
				'full_name' :_get_arch(
					part_props['FAMILY'],
					part_props['ARCHITECTURE_FULL_NAME']
				),
				'short_name': part_props['ARCHITECTURE']
			},
			'package': {
				'name'      : part_props['PACKAGE'],
				'pinout_ver': part_props['PACKAGE_PINOUT_VERSION'],
				'delay_ver' : part_props['PACKAGE_PIN_DELAY_VERSION'],
			},
			'config_modes': part_props['AVAILABLE_CONFIG_MODES'],
			'class'       : part_props['CLASS'],
			'geometry'    : {
				'cols'      : int(part_props['COLS']),
				'rows'      : int(part_props['ROWS']),
				'block_ram' : int(part_props['BLOCK_RAMS']),
				'ultra_ram' : int(part_props.get('ULTRA_RAMS', 0)),
				'dsp'       : int(part_props['DSP']),
				'ff'        : int(part_props['FLIPFLOPS']),
				'lut'       : int(part_props['LUT_ELEMENTS']),
				'slices'    : int(part_props['SLICES']),
				'slrs'      : int(part_props['SLRS']),
				'mcbs'      : part_props['MCBS'],
				'mmcm'      : part_props['MMCM'],
			},
			'compatible': part_props['COMPATIBLE_PARTS'].split(' '),
			'idcode'    : {
				'extended': part_props['EXTENDED_IDCODE'],
				'normal'  : part_props['IDCODE']
			},
			'transceivers': {
				'GB'   : int(part_props.get('GB_TRANSCEIVERS',    0)),
				'GTHE2': int(part_props.get('GTHE2_TRANSCEIVERS', 0)),
				'GTHE3': int(part_props.get('GTHE3_TRANSCEIVERS', 0)),
				'GTHE4': int(part_props.get('GTHE4_TRANSCEIVERS', 0)),
				'GTM'  : int(part_props.get('GTM_TRANSCEIVERS',   0)),
				'GTME5': int(part_props.get('GTME5_TRANSCEIVERS', 0)),
				'GTPE2': int(part_props.get('GTPE2_TRANSCEIVERS', 0)),
				'GTXE2': int(part_props.get('GTXE2_TRANSCEIVERS', 0)),
				'GTYE3': int(part_props.get('GTYE3_TRANSCEIVERS', 0)),
				'GTYE4': int(part_props.get('GTYE4_TRANSCEIVERS', 0)),
				'GTYE5': int(part_props.get('GTYE5_TRANSCEIVERS', 0)),
				'GTYP' : int(part_props.get('GTYP_TRANSCEIVERS',  0)),
				'GTZE2': int(part_props.get('GTZE2_TRANSCEIVERS', 0)),
			},
			'io': {
				'pins'     : int(part_props['IO_PIN_COUNT']),
				'standards': part_props['IO_STANDARDS'].split(' ')
			},
			'vivado_license': part_props.get('LICENSE', ''),
			'temp': {
				'grade'   : part_props['TEMPERATURE_GRADE_LETTER'],
				'ref': int(part_props['REF_OPERATING_TEMPERATURE']),
				'max': int(part_props['MAX_OPERATING_TEMPERATURE']),
			},
			'voltage': {
				'max': float(part_props['MAX_OPERATING_VOLTAGE']),
				'min': float(part_props['MIN_OPERATING_VOLTAGE']),
				'ref': float(part_props['REF_OPERATING_VOLTAGE']),
			},
			'buses': {
				'pci'   : int(part_props.get('PCI_BUSES', 0)),
				'temac' : int(part_props['TEMAC_NETWORK_CONTROLLERS'])
			},
		}

		return (True, part_data)

	def _update_progress(f):
		success, data = f.result()
		if success:
			index['devices'].append(data)
			progress.advance(task, 1)

	log.info('Normalizing')
	futures = []
	with ThreadPoolExecutor(args.parallel_jobs) as pool:
		for part in part_files:
			f = pool.submit(_normalize_part, part)
			f.add_done_callback(_update_progress)
			futures.append(f)

	success = all(map(lambda f: f.result()[0], futures))

	progress.remove_task(task)

	log.info(f'Writing index file {NORMALIZED_INDEX}')
	with NORMALIZED_INDEX.open('w') as index_file:
		json.dump(index, index_file)

	return success

def dedupe_index(args, progress : Progress):
	task = progress.add_task(description = 'Deduplicating part index')

	log.info(f'Loading parts index from {NORMALIZED_INDEX}')
	with NORMALIZED_INDEX.open('r') as pl:
		parts_list = json.load(pl)

	dev_count = len(parts_list['devices'])
	log.info(f'Loaded {dev_count} devices')
	progress.update(task, total = dev_count)

	devs = {}

	rm_task = progress.add_task('Collecting common devices', total = dev_count)
	for dev in parts_list['devices']:
		if dev['device'] not in devs:
			devs[dev['device']] = []
		devs[dev['device']].append(dev)
		progress.advance(rm_task, advance = 1)
	progress.remove_task(rm_task)

	deduped = {
		'version'  : parts_list['version'],
		'generated': datetime.now().isoformat(),
		'devices'  : []
	}

	log.info(f'Found {len(devs)} unique devices')
	diff_task = progress.add_task('Differencing common devices', total = len(devs.keys()))
	for d, d_list in devs.items():
		progress.update(diff_task, description = f'Differencing common devices [{d}]')
		progress.advance(diff_task, advance = 1)

		unified_device = {
			'family'       : d_list[0]['family'],
			'c_family'     : d_list[0]['c_family'],
			'device'       : d,
			'arch'         : d_list[0]['arch'],
			'config_modes' : d_list[0]['config_modes'],
			'packages'     : {},
		}

		for d in d_list:
			progress.advance(task, advance = 1)
			pkg = unified_device['packages'].setdefault(
				d['package']['name'], {}
			)

			speed_grade = d['speed']['grade']
			speeds = pkg.setdefault('speeds', {})
			speeds[speed_grade] = d['speed']
			speeds[speed_grade].pop('grade')
			speeds[speed_grade]['voltage'] = d['voltage']

			geometry = pkg.setdefault('geometry', {})
			if len(geometry) == 0:
				geometry.update(d['geometry'])
			else:
				diff = set(geometry.items()) ^ set(d['geometry'].items())
				if len(diff) > 0:
					log.error('Geometry Mismatch!')
					log.error(diff)
					return False

			compatible = pkg.setdefault('compatible', [])
			diff =  set(d['compatible']) - set(compatible)
			compatible.extend(diff)


			idcode = pkg.setdefault('idcode', {})
			if len(idcode) == 0:
				idcode.update(d['idcode'])
			else:
				diff = set(idcode.items()) ^ set(d['idcode'].items())
				if len(diff) > 0:
					log.error('IDCode Mismatch!')
					log.error(diff)
					return False

			transceivers = pkg.setdefault('transceivers', {})
			if len(transceivers) == 0:
				transceivers.update(d['transceivers'])
			else:
				diff = set(transceivers.items()) ^ set(d['transceivers'].items())
				if len(diff) > 0:
					log.error('Transceivers Mismatch!')
					log.error(diff)
					return False

			io = pkg.setdefault('io', {})
			if len(io) == 0:
				io.update(d['io'])
			else:
				assert io['pins'] == d['io']['pins'], 'Package pin count differs'
				diff = set(io['standards']) ^ set(d['io']['standards'])
				if len(diff) > 0:
					log.error('IO Mismatch!')
					log.error(diff)
					return False

			pkg.setdefault('temp', {})[d['part']] = d['temp']


			buses = pkg.setdefault('buses', {})
			if len(buses) == 0:
				buses.update(d['buses'])
			else:
				diff = set(buses.items()) ^ set(d['buses'].items())
				if len(diff) > 0:
					log.error('Buses Mismatch!')
					log.error(diff)
					return False

		deduped['devices'].append(unified_device)
		with DEDUPED_INDEX.open('w') as f:
			json.dump(deduped, f)

	progress.remove_task(diff_task)
	progress.remove_task(task)
	return True

def _nomalize_family(family):
	return {
		'aartix7'          : ('artix',   ('Automotive'   , None         )),
		'akintex7'         : ('kintex',  ('Automotive'   , None         )),
		'artix7'           : ('artix',   (None           , None         )),
		'artix7l'          : ('artix',   ('Low Power'    , None         )),
		'artixuplus'       : ('artix',   ('UltraScale+'  , None         )),
		'aspartan7'        : ('spartan', ('Automotive'   , None         )),
		'azynq'            : ('zynq',    ('Automotive'   , None         )),
		'azynquplus'       : ('zynq',    ('UltraScale+'  , None         )),
		'kintex7'          : ('kintex',  (None           , None         )),
		'kintex7l'         : ('kintex',  ('Low Power'    , None         )),
		'kintexu'          : ('kintex',  ('UltraScale'   , None         )),
		'kintexuplus'      : ('kintex',  ('UltraScale+'  , None         )),
		'qartix7'          : ('artix',   ('Defense Grade', None         )),
		'qkintex7'         : ('kintex',  ('Defense Grade', None         )),
		'qkintex7l'        : ('kintex',  ('Defense Grade', 'Low Power'  )),
		'qkintexu'         : ('kintex',  ('Defense Grade', 'UltraScale' )),
		'qkintexuplus'     : ('kintex',  ('Defense Grade', 'UltraScale+')),
		'qrkintexu'        : ('kintex',  ('Rad-Hard',      'UltraScale' )),
		'qrversalaicore'   : ('versal',  ('Rad-Hard',      'AI Core'    )),
		'qversalaicore'    : ('versal',  ('Defense Grade', 'AI Core'    )),
		'qversalprime'     : ('versal',  ('Defense Grade', 'Prime'      )),
		'qvirtex7'         : ('virtex',  ('Defense Grade', None         )),
		'qvirtexuplus'     : ('virtex',  ('Defense Grade', 'UltraScale+')),
		'qvirtexuplusHBM'  : ('virtex',  ('UltraScale+',   'HBM'        )),
		'qzynq'            : ('zynq',    ('Defense Grade', None         )),
		'qzynquplus'       : ('zynq',    ('UltraScale+',   None         )),
		'qzynquplusRFSOC'  : ('zynq',    ('UltraScale+',   'RFSoC'      )),
		'spartan7'         : ('spartan', (None,            None         )),
		'versalaicore'     : ('versal',  ('AI Core',       None         )),
		'versalaiedge'     : ('versal',  ('AI Edge',       None         )),
		'versalpremium'    : ('versal',  ('Premium',       None         )),
		'versalprime'      : ('versal',  ('Prime',         None         )),
		'virtex7'          : ('virtex',  (None,            None         )),
		'virtexu'          : ('virtex',  ('UltraScale',    None         )),
		'virtexuplus'      : ('virtex',  ('UltraScale+',   None         )),
		'virtexuplus58g'   : ('virtex',  ('UltraScale+',   '58G'        )),
		'virtexuplusHBM'   : ('virtex',  ('UltraScale+',   'HBM'        )),
		'zynq'             : ('zynq',    (None,            None         )),
		'zynquplus'        : ('zynq',    ('UltraScale+',   None         )),
		'zynquplusRFSOC'   : ('zynq',    ('UltraScale+',  'RFSoC'       )),
		'virtexuplusHBMes1': ('virtex',  ('UltraScale+', 'HBM es1'      )),
	}.get(family, ('unknown', (None, None)))

def split_families(args, progress : Progress):
	task = progress.add_task(description = 'Splitting part index by family', start = False)

	if not SPLIT_DIR.exists():
		SPLIT_DIR.mkdir()

	with DEDUPED_INDEX.open('r') as f:
		part_index = json.load(f)

	devs = part_index['devices']

	families = []
	fm_task = progress.add_task(f'Collecting families', total = len(devs))
	for p in devs:
		families.extend(set([p['family']]) - set(families))
		progress.advance(fm_task)
	progress.remove_task(fm_task)

	log.info(f'Found {len(families)} device families')

	split = {}

	log.info('Splitting devices into families')
	sp_task = progress.add_task(f'Splitting families', total = len(devs))
	for d in devs:
		fam = split.setdefault(_nomalize_family(d['family'])[0], [])
		fam.append(d)
		progress.advance(sp_task)
	progress.remove_task(sp_task)


	for f, devs in split.items():
		log.info(f'Saving family {f}')
		fam_index = {
			'version'  : part_index['version'],
			'generated': datetime.now().isoformat(),
			'devices'  : devs
		}
		with (SPLIT_DIR / f'{f}_index.json').open('w') as f:
			json.dump(fam_index, f)

	progress.remove_task(task)
	return True


def serialize_indices(args, progress : Progress):
	task = progress.add_task(description = 'Serializing part indices')

	if not SERIALIZED_DIR.exists():
		SERIALIZED_DIR.mkdir()

	def _serialize(obj, file : Path):
		compressor = ZstdCompressor(19)
		buffer = BytesIO()
		# Pack into msgback
		pack(obj, buffer)
		buffer.seek(0)

		# Write out the compressed file
		with file.open('wb') as f:
			compressor.copy_stream(buffer, f)


	log.info('Seralizing unified index')
	with DEDUPED_INDEX.open('r') as f:
		index = json.load(f)

	unified_index = (SERIALIZED_DIR / 'part_index.xcm')
	_serialize(index, unified_index)
	unified_index.rename((XYLENE_DB_DIR / unified_index.name))

	for idx in SPLIT_DIR.glob('*.json'):
		family = idx.stem.split("_")[0]
		log.info(f'Seralizing index {family}')
		with idx.open('r') as f:
			file = (SERIALIZED_DIR / f'{idx.stem}.xcm')
			_serialize(json.load(f),  file)
			file.rename((XYLENE_DB_DIR / family / 'part_index.xcm'))

	return True

def mkpartindex_main(args):

	with Progress(
		SpinnerColumn(),
		TextColumn('[progress.description]{task.description}'),
		BarColumn(bar_width = None),
		TextColumn('[{task.completed:04}/{task.total:04}]'),
		TextColumn('[progress.percentage]{task.percentage:>3.0f}%'),
		transient = True
	) as progress:
		task = progress.add_task('Extracting Parts', start = False, total = 6)

		if not gen_part_list(args, progress):
			log.error('Unable to extract parts database')
			return 1
		progress.advance(task, advance = 1)

		if not gen_part_props(args, progress):
			log.error('Unable to extract parts database')
			return 1

		progress.advance(task, advance = 1)


		if not normalize_parts(args, progress):
			log.error('Unable to normalize parts index')
			return 1

		progress.advance(task, advance = 1)

		if not dedupe_index(args, progress):
			log.error('Unable to deduplicate part index')
			return 1

		progress.advance(task, advance = 1)

		if not split_families(args, progress):
			log.error('Unable to split part index')
			return 1

		progress.advance(task, advance = 1)

		if not serialize_indices(args, progress):
			log.error('Unable to serialize part indices')
			return 1

		progress.advance(task, advance = 1)


	return 0


def mkpartindex_parser(parser):
	parser.add_argument(
		'--parallel-jobs', '-P',
		type    = int,
		default = (cpu_count() // 4),
		help    = 'Number of parallel instances of Vivado to run'
	)

if __name__ == '__main__':
	sys.exit(main(
		mkpartindex_main,
		'mkpartindex',
		'Generate the Xylene device index',
		mkpartindex_parser
	))
